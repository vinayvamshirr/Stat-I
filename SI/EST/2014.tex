\section*{2014}
\vspace{-.5cm}
\hrulefill \smallskip\\
\ques{1}{d}{10} Let $X_1$ and $X_2$ be i.i.d. random variables and each has probability density function \[ \begin{aligned} f(x;\theta) &= \dfrac{1}{\theta}\exp{\left(-\dfrac{x}{\theta}\right)}, \enskip x\geq0, \enskip \theta>0 \\
&= 0, \enskip \text{otherwise.}
\end{aligned} \] If $U_1 = 0.6X_1 + 0.4X_2$ and $U_2 = X_1 + X_2$, decide which one of $U_1$ and $U_2$ are sufficient statistics for $\theta$.\\ If $h(u_2) = E(U_1|u_2)$, then show that it ahs smaller variance compared to Var($U_1$).
\myline
\ques{3}{a}{20} Suppose $n$ items are put on test simultaneously and test is continued until $r$ items fail. Assuming an exponential failure distribution with mean life time $\theta$, obtain the maximum likelihood estimator for $\theta$ and hence estimate P($X\geq t$). Also obtain the Fisher Information about the parameter $\theta$ and show that the estimator is asymptotically normal.
\myline
\ques{3}{b}{15} Let $X\sim \mathcal{N}(\mu,1)$ and the prior distribution of $\mu$ is $\mathcal{N}(0,1)$. Assuming squared error loss function, obtain the Bayes estimator for $\mu$. Also obtain Bayes risk.