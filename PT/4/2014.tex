\section*{2014}
\vspace{-.5cm}
\hrulefill \smallskip\\
\ques{2}{a}{20} The probability density function of a random variable $X$ is given by \[ \begin{aligned} f_X(x) &= 630x^4(1 -x)^4 , \enskip 0 < x < 1, \\
&= 0 , \enskip \text{otherwise.}
\end{aligned} \] Find the probability that $X$ will take on a value within two standard deviations of the mean $(\mu \pm 2\sigma)$ and compare it with the lower bound provided by the Chebychev's Inequality.
\myline
\ques{2}{b}{15} For a random variable $X$ with probability density function \[ \begin{aligned} f_X(x;\lambda) &= e^{-x}.\dfrac{x^{\lambda}}{\lambda!}, \enskip x > 0; \\
&= 0, \enskip \text{otherwise;}
\end{aligned}\] where $\lambda \geq 0$ is an integer, show that \[ P_r \left\{0 < X < 2(\lambda + 1) \right\} > \dfrac{\lambda}{\lambda + 1}.\]
\myline
\ques{3}{c}{15} Define convergence in probability and convergence in distribution of a sequence of random variables. Show that convergenc e of $X_n$ to $X$ in probability implies convergence of $X_n$ to $X$ in distribution. Is the converse also true?